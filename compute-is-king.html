<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <title>A Future Battle For Compute</title>
    <link rel="stylesheet" href="/assets/css/styles.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@400;500;700&display=swap" rel="stylesheet">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" />
    <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>A Future Battle For Compute</title>
<meta name="generator" content="Jekyll v4.2.2" />
<meta property="og:title" content="A Future Battle For Compute" />
<meta name="author" content="Jack Hullis" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Artificial superintelligence is, by definition, artificial intelligence that far exceeds human intelligence. If artificial super intelligence one day becomes a reality, we will find ourselves far too inferior to defend ourselves from it intellectually. Instead, we will have to employ the help of another artificial superintelligent agent." />
<meta property="og:description" content="Artificial superintelligence is, by definition, artificial intelligence that far exceeds human intelligence. If artificial super intelligence one day becomes a reality, we will find ourselves far too inferior to defend ourselves from it intellectually. Instead, we will have to employ the help of another artificial superintelligent agent." />
<link rel="canonical" href="http://localhost:4000/compute-is-king" />
<meta property="og:url" content="http://localhost:4000/compute-is-king" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-08-11T00:00:00+01:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="A Future Battle For Compute" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Jack Hullis"},"dateModified":"2022-08-11T00:00:00+01:00","datePublished":"2022-08-11T00:00:00+01:00","description":"Artificial superintelligence is, by definition, artificial intelligence that far exceeds human intelligence. If artificial super intelligence one day becomes a reality, we will find ourselves far too inferior to defend ourselves from it intellectually. Instead, we will have to employ the help of another artificial superintelligent agent.","headline":"A Future Battle For Compute","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/compute-is-king"},"url":"http://localhost:4000/compute-is-king"}</script>
<!-- End Jekyll SEO tag -->

    
  </head>
  <header>
    <nav>
    <div class="logo">Jack Hullis' Blog</div>
    <a class="return" href="https://arinteli.com"/>Back to arinteli >>></a>
      
        <li class="menu-item"><a href="/" >Home</a></li>
      
        <li class="menu-item"><a href="/blog" >Blog</a></li>
      
        <li class="menu-item"><a href="/about" >About</a></li>
      
  </nav>
  </header>
  <body contenteditable="false">
    <div class="content">
      <h1>A Future Battle For Compute</h1>
<p id="date-author">11 Aug 2022 - Jack Hullis</p>

<div class="sidebar">
    <ul id="toc" class="toc__list">
<li class="toc-entry toc-h2"><a href="#regulation">Regulation</a></li>
<li class="toc-entry toc-h2"><a href="#a-ceiling-for-intelligence">A ceiling for intelligence?</a></li>
</ul>
    </div>


<p>Artificial superintelligence is, by definition, artificial intelligence that far exceeds human intelligence. If artificial super intelligence one day becomes a reality, we will find ourselves far too inferior to defend ourselves from it intellectually. Instead, we will have to employ the help of another artificial superintelligent agent.</p>

<p>This scenario sets the scene for an artificial intelligence cold war, which on the internet will stage itself as a constant battle between AI-developed security systems and AI-developed hacking systems.</p>

<p>The AI agents on both sides are likely to be very similar in their technical abilities. Both agents need knowledge of how to find vulnerabilities and how they can be exploited. The difference would come in the instructions that we humans give them.</p>

<p>However, it is unlikely that these two agents would actually be the same. Instead, security companies will develop their agents, which they will keep for use only by themselves to keep their methods and secrets hidden. In response, hackers will likely do the same.</p>

<p>The more compute and data you can access, the bigger and better the agent you can train. It is therefore vital for each side to obtain as much computing power and as much data as possible.</p>

<p>If the security agent is more potent (assuming the security agent knows everything the hacking agent knows and more), then given an unlimited time, the hacking agent will not be able to break in. And in the case where the hacking agent is more potent, the opposite is true.</p>

<p>In the above example, we would prefer it if the security agent was more potent than the hacking one. If it isn’t, then none of the internet can be trusted, rendering it useless for many things, especially e-commerce. So, how can we ensure that the security agent is more potent?</p>

<h2 id="regulation">Regulation</h2>

<p>As we have already discussed, the two factors of agent intelligence are compute and data. Unfortunately, data is difficult to control, with much of it being readily accessible (internet, books, etc.), and with the future possibility of much of the data being AI-generated itself. So if we can’t control data, let’s look toward computing.</p>

<p>The amount of compute needed to train current-day models is already very high. For example, OpenAI’s GPT-3 (175M) cost 3.14E23 FLOPs to train, which may have cost them around $5 million. With this much compute needed, it’s no surprise that these models are trained on highly specialised machine learning GPUs, such as Nvidia’s Tesla V100.</p>

<p>Governments or other regulating bodies could restrict how much compute organisations can own. Restrictions would prevent organisations that do not meet set criteria from purchasing more than a set amount. This would be similar to how some countries restrict the amount of land an organisation can own to prevent large organisations from having too much control. The idea here is that preventing organisations from having too much compute could help prevent bad actors from getting as much access to compute as security companies do.</p>

<p>However, it is essential to note that such a policy could have unintended consequences, and it must be carefully considered before implementation. For example, a black market for compute may emerge, which bad actors could use to obtain the compute they need. Restrictions might also incentivise the creation of botnets, in which consumers’ hardware is unknowingly hijacked and utilised. However, perhaps the growing trend of cloud computing will make botnets obsolete.</p>

<h2 id="a-ceiling-for-intelligence">A ceiling for intelligence?</h2>

<p>All of this is based on the assumption that intelligence will continue to grow by increasing compute and data abundance. And will it always be true that a more intelligent AI consistently outperforms a less intelligent AI?</p>

<p>Let us take, for example, a seemingly trivial task like colour recognition. An agent that can correctly identify all colours at 5,000 parameters will be no worse than one that can do it at 1M parameters. However, we can recognise in this case that AI agents will not be able to improve their output with further training. This is because there are set truths that the agent must learn (yellow is yellow, blue is blue, etc.) and nothing more beyond that.</p>

<p>Now take a more difficult task, such as building an impenetrable security system. But, despite being a more complex problem, what if there are set truths here too? Too complicated for us as humans to see, but not for a machine. If set truths exist for this example too, there must also be a point where no matter how much training the agent is given, it cannot improve upon its output.</p>

<p>ASI is likely to reach a level of intelligence where further training can no longer improve upon mundane tasks, such as programming. Unfortunately, we cannot tell how long it will take to get to this level. It could be years, decades, or even centuries, and it is also not known where the limit of intelligence on such tasks lies or if a limit even exists in the first place.</p>

    </div>
    <hr>
    <footer>Powered by HTML and Jekyll</footer>
  </body>
</html>

